{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìå What is Stacking in Ensemble Learning?\n",
    "\n",
    "**Stacking (Stacked Generalization)** is an **Ensemble Learning** technique that combines multiple machine learning models to improve predictive performance.  \n",
    "Unlike **Bagging** and **Boosting**, which use simple voting or averaging, **Stacking** uses a **meta-model** to learn how to best combine the predictions of base models.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è How Does Stacking Work?\n",
    "Stacking follows a **two-layer architecture**:\n",
    "\n",
    "1Ô∏è‚É£ **Base Models (Level-0 Models)**  \n",
    "   - Multiple different models (**e.g., Decision Trees, SVM, Neural Networks**) are trained on the dataset.  \n",
    "   - These models make predictions, which are then used as **features** for the next layer.\n",
    "\n",
    "2Ô∏è‚É£ **Meta-Model (Level-1 Model)**  \n",
    "   - A higher-level model (**often a simple Linear Regression or Logistic Regression**) learns how to combine the predictions from base models.  \n",
    "   - It **does not see the original dataset** but learns from the outputs of the base models.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Advantages of Stacking\n",
    "‚úÖ **Combines strengths** of different models to improve performance.  \n",
    "‚úÖ **More flexible** than Bagging and Boosting because it allows heterogeneous models.  \n",
    "‚úÖ **Reduces overfitting**, as base models are diverse.\n",
    "\n",
    "‚ùå **Computationally expensive**, as multiple models need to be trained.  \n",
    "‚ùå **Complex to tune**, requiring careful selection of base and meta-models.  \n",
    "‚ùå **Risk of overfitting**, if meta-model is too complex or if base models are not diverse enough.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Example: Implementing Stacking in Python\n",
    "You can implement **Stacking** using **Scikit-learn** as follows:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svm', SVC(probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create Stacking model\n",
    "stacking = StackingClassifier(estimators=base_models, final_estimator=meta_model, passthrough=True)\n",
    "\n",
    "# Train the model\n",
    "stacking.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = stacking.predict(X_test)\n",
    "print(f'Stacking Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
