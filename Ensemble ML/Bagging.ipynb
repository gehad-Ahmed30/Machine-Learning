{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìå What is Bagging (Bootstrap Aggregating)?\n",
    "\n",
    "**Bagging (Bootstrap Aggregating)** is an **Ensemble Learning** technique that improves model accuracy and reduces variance by training multiple models on different subsets of the data and averaging their predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è How Does Bagging Work?\n",
    "Bagging follows these key steps:\n",
    "\n",
    "1Ô∏è‚É£ **Bootstrap Sampling**  \n",
    "   - Multiple **random subsets** of the original dataset are created **with replacement**.  \n",
    "   - Some data points may appear **multiple times**, while others may be **excluded**.\n",
    "\n",
    "2Ô∏è‚É£ **Model Training**  \n",
    "   - A separate **base model** (often the same type of model) is trained on each subset.\n",
    "\n",
    "3Ô∏è‚É£ **Aggregation of Predictions**  \n",
    "   - For **classification**, predictions are combined using **Voting**:\n",
    "     - **Hard Voting**: The most common class is chosen.\n",
    "     - **Soft Voting**: The class with the highest probability is chosen.\n",
    "   - For **regression**, predictions are combined using the **average**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Advantages of Bagging\n",
    "‚úÖ **Reduces variance** by averaging predictions, making the model more stable.  \n",
    "‚úÖ **Prevents overfitting**, especially in high-variance models like **Decision Trees**.  \n",
    "‚úÖ Works well with **complex models** that can easily overfit.  \n",
    "\n",
    "‚ùå **Less effective on low-variance models** (e.g., Linear Regression).  \n",
    "‚ùå Training multiple models increases computational cost.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Example: Implementing Bagging in Python\n",
    "Here‚Äôs how to use Bagging with a **Decision Tree Classifier** in **Scikit-learn**:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Bagging Classifier with Decision Trees\n",
    "bagging = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(),  # Base model\n",
    "    n_estimators=10,  # Number of models\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = bagging.predict(X_test)\n",
    "print(f'Bagging Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## descsion tree, regression tree , linear regression , neural net   + used in overfiting\n",
    "## not used stable (k nearest)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
